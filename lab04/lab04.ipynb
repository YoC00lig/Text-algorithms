{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity Metrics\n",
    "\n",
    "Exercise notebook\n",
    "\n",
    "Course: Algorytmy Tekstowe at AGH University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and vectorization\n",
    "\n",
    "1. Preprocessing: Convert the text documents to lowercase and remove all punctuation marks (using regular expressions, for example).\n",
    "2. Vocabulary creation: Create a vocabulary by taking all unique words from all text documents.\n",
    "3. Word frequency vectors: Create two vectors, each representing the frequency of each word in the vocabulary in each text document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove all punctuation marks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def text_to_vec(docs: list[str]) -> list[list[int]]:\n",
    "    # Create vocabulary\n",
    "    vocab = set()\n",
    "    for doc in docs:\n",
    "        doc = preprocess(doc)\n",
    "        words = doc.split()\n",
    "        vocab.update(words)\n",
    "    \n",
    "    # Create word frequency vectors\n",
    "    freq_vecs = []\n",
    "    for doc in docs:\n",
    "        doc = preprocess(doc)\n",
    "        words = doc.split()\n",
    "        word_counts = Counter(words)\n",
    "        freq_vec = [word_counts[word] for word in vocab]\n",
    "        freq_vecs.append(freq_vec)\n",
    "    \n",
    "    return freq_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "text_a = \"The quick brown fox jumped over the lazy dog.\"\n",
    "text_b = \"The lazy dog was jumped over by the quick brown fox.\"\n",
    "vec_a, vec_b = text_to_vec([text_a, text_b])\n",
    "\n",
    "\n",
    "assert(set(vec_a) == set([1, 1, 1, 2, 1, 1, 1, 1, 0, 0]))\n",
    "assert(set(vec_b) == set([1, 1, 1, 2, 1, 1, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}= \\frac{\\sum\\limits_{i=1}^{n} A_i B_i}{\\sqrt{\\sum\\limits_{i=1}^{n} A_i^2} \\sqrt{\\sum\\limits_{i=1}^{n} B_i^2}}\n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &\\mathbf{A}\\text{ and }\\mathbf{B} \\text{ are the two vectors being compared}\\\\\n",
    "    &n \\text{ is the dimensionality of the vectors}\\\\\n",
    "    &\\theta \\text{ represents the angle between two vectors } \\mathbf{A} \\text{ and } \\mathbf{B} \\text{ in a high-dimensional space}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The dot product of $\\mathbf{A}$ and $\\mathbf{B}$ is divided by the product of their Euclidean lengths to normalize the result to a range of [-1, 1]. A value of 1 indicates that the two vectors are identical, while a value of -1 indicates that they are completely dissimilar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_similarity(text_a: str, text_b: str) -> float:\n",
    "    freq_vecs = text_to_vec([text_a, text_b])\n",
    "    dot_product = sum(a * b for a, b in zip(freq_vecs[0], freq_vecs[1]))\n",
    "    \n",
    "    norm_a = math.sqrt(sum(a ** 2 for a in freq_vecs[0]))\n",
    "    norm_b = math.sqrt(sum(b ** 2 for b in freq_vecs[1]))\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "dist = cosine_similarity(text_a, text_b)\n",
    "assert(abs(dist - 0.91986) < 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice coefficient / SÃ¸rensen-Dice Index\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\text{Dice}(A, B) = \\frac{2 |A \\cap B|}{|A| + |B|} \n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &A \\text{ and } B \\text{ represent the two sets being compared} \\\\\n",
    "    &|A| \\text{ and } |B| \\text{ represent the cardinality (number of elements) of the sets} \\\\\n",
    "    &\\text{and } |A \\cap B| \\text{ represents the size of the intersection of the two sets}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dice(text_a: str, text_b: str) -> float:\n",
    "    text_a = preprocess(text_a)\n",
    "    text_b = preprocess(text_b)\n",
    "    \n",
    "    set_a = set(text_a.split())\n",
    "    set_b = set(text_b.split())\n",
    "    \n",
    "    intersection_ = len(set_a.intersection(set_b))\n",
    "    union_ = len(set_a) + len(set_b)\n",
    "    \n",
    "    return 2 * intersection_ / union_\n",
    "\n",
    "dice(text_a, text_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "dist = dice(text_a, text_b)\n",
    "assert(abs(dist - 0.88888) < 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}\n",
    "    \\qquad\\begin{aligned}\n",
    "    &\\text{where:} \\\\\n",
    "    &d(x,y) \\text{ is the Euclidean distance} \\\\\n",
    "    &x_i, y_i \\text{ are the values of the i-th dimension of vectors } x \\text{ and } y \\\\\n",
    "    &n \\text{ is the number of dimensions in the vectors}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(text_a: str, text_b: str) -> float:\n",
    "    x, y = text_to_vec([text_a, text_b])\n",
    "\n",
    "    dist = 0\n",
    "    for i in range(len(x)):\n",
    "        dist += (x[i] - y[i]) ** 2\n",
    "\n",
    "    return math.sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "dist = euclidean_distance(text_a, text_b)\n",
    "assert(abs(dist - 1.4142135) < 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCS - Longest Common Subsequence\n",
    "\n",
    "Longest, common, continuous subsequence of two sequences, aka \"the longest substring\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Sequence\n",
    "\n",
    "def lcs(seq_a: Sequence[Any], seq_b: Sequence[Any]) -> int:\n",
    "    n = len(seq_a)\n",
    "    m = len(seq_b)\n",
    "    dp = [[0] * (m+1) for _ in range(n+1)]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if seq_a[i] == seq_b[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def word_lcs(text_a: str, text_b: str) -> int:\n",
    "    # Split the texts into words\n",
    "    seq_a = text_a.split()\n",
    "    seq_b = text_b.split()\n",
    "\n",
    "    return lcs(seq_a, seq_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "assert lcs(\"banana\", \"ananas\") == 5\n",
    "assert word_lcs(text_a, text_b) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davies-Bouldin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import sqrt\n",
    "\n",
    "def centroid(points: List[List[float]]) -> List[float]:\n",
    "    n = len(points[0])\n",
    "    center = [0.0] * n\n",
    "    for point in points:\n",
    "        center = [c + p for c, p in zip(center, point)]\n",
    "\n",
    "    return [c / len(points) for c in center]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
